# coding: utf-8
from utils import restore_model

model,enc_model,dec_model = restore_model(path_to_full_model="model_checkpoints/seq2seq_epoch_100.h5",hidden_size=512)

# If you want to save the model graph as an image uncomment the 2 lines below
#from tensorflow import keras
#keras.utils.plot_model(model, "model.png",show_shapes=True)

#def get_gate_weights(model):
units = int(int(model.get_layer("encoder_lstm_1").trainable_weights[0].shape[1])/4)
W = model.get_layer("encoder_lstm_1").get_weights()[0]
U = model.get_layer("encoder_lstm_1").get_weights()[1]
b = model.get_layer("encoder_lstm_1").get_weights()[2]

W_i = W[:, :units]
W_f = W[:, units: units * 2]
W_c = W[:, units * 2: units * 3]
W_o = W[:, units * 3:]

U_i = U[:, :units]
U_f = U[:, units: units * 2]
U_c = U[:, units * 2: units * 3]
U_o = U[:, units * 3:]

b_i = b[:units]
b_f = b[units: units * 2]
b_c = b[units * 2: units * 3]
b_o = b[units * 3:]

# Get single weights(input->lstm) vs time step arrays, is it W_i.T ? Yes it is.
#arr=[]
#for j in W_i.shape[-1]: arr.append(W_i[:,j])
# OR more concisely: arr = W_i.transpose()

